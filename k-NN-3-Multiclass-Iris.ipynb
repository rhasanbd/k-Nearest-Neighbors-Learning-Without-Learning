{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN - Multiclass Classification - Iris Dataset\n",
    "\n",
    "In this notebook, we use Scikit-Learn to introduce various steps of Machine Learning for performing **multi-class classification** using the k-Nearest Neighbors (k-NN) model. The steps include:\n",
    "\n",
    "- Creating a test dataset\n",
    "- Creating the KNN classifier model\n",
    "- Model selection via hyperparameter tuning\n",
    "- Evaluate a KNN model using accuracy, precision, recall, F1 score, and confusion matrix\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We will use the Iris dataset, which is a multivariate data set. It is a famous dataset that contains the sepal and petal length and width of 150 Iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica\n",
    "\n",
    "There are 4 features: \n",
    "- sepal length (cm)\n",
    "- sepal width (cm)\n",
    "- petal length (cm)\n",
    "- petal width (cm)\n",
    "\n",
    "Total number of samples: 150\n",
    "\n",
    "The target (label) is coded as follows:\n",
    "- Setosa: 0\n",
    "- Versicolor: 1\n",
    "- Virginica: 2\n",
    "\n",
    "\n",
    "The dataset is also known as Fisher's Iris data set as it was introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis\".\n",
    "\n",
    "\n",
    "<img src=\"http://engineering.unl.edu/images/uploads/IrisFlowers.png\" width=800, height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/2ty0m0yn1jzc2zjgq1154kkxxmbbr2/T/ipykernel_18406/3171066688.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First load the data and explore the feature names, target names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# The key values\n",
    "print(list(iris.keys()))\n",
    "\n",
    "# The feature names\n",
    "print(list(iris.feature_names))\n",
    "\n",
    "# The target names\n",
    "print(list(iris.target_names))\n",
    "\n",
    "# The target values (codes)\n",
    "#print(list(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Data Matrix and the Target Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Data Matrix\n",
    "X = iris[\"data\"]\n",
    "\n",
    "# Target Array\n",
    "y = iris[\"target\"] \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Dataset\n",
    "\n",
    "We use sklearn's train_test_split function to split the dataset into training and test subsets. The data is shuffled by default before splitting.\n",
    "\n",
    "This function splits arrays or matrices into **random** train and test subsets.\n",
    "\n",
    "For the **reproducibility of the results**, we need to use the same seed for the random number generator. The seed is set by the \"random_state\" parameter of the split function. \n",
    "\n",
    "However, in repeated experiments, if we don't want to use the same train and test subsets, then we drop the \"random_state\" parameter from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Data\n",
    "\n",
    "\n",
    "Before applying K-NN on the data we should standardize it. We use Scikit-Learn's StandardScaler object for this purpose. Following methods of this object are used: fit() & transform(). \n",
    "- The fit() method computes the mean and standard deviation\n",
    "- The transform() method performs standardization by centering and scaling (0 mean and unit variance)\n",
    "\n",
    "It is important to note that the **fit() method must be applied to the training data only**. In other words, the mean and standard deviation should be computed only based on the training data, not using the full dataset that includes test data. Once the mean and standard deviation are computed from the training data, we use them to transform the training set and the test set (and any subsequent new data) **separately**.\n",
    "\n",
    "### Why do we apply the fit() method only on the training data?\n",
    "We compute the mean and standard deviation using only the training data to prevent data leakage. If we use the full dataset, these values will contain information about the test subset. It will influence the learning and prediction. The learned model might overfit as it is based on the full dataset (via mean and standard deviation). We must ensure that learning is solely based on training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Classification Using Scikit-Learn \n",
    "\n",
    "The scikit-learn implements two different nearest neighbors classifiers: \n",
    "- KNeighborsClassifier implements learning based on the  nearest neighbors of each query point, where k is an **integer** value specified by the user. \n",
    "- RadiusNeighborsClassifier implements learning based on the number of neighbors within a fixed radius  of each training point, where k is a **floating-point** value specified by the user. This technique is suitable for scenarios in which data is not uniformly sampled.\n",
    "\n",
    "In this notebook, we will use the KNeighborsClassifier.\n",
    "\n",
    "## KNeighborsClassifier Hyperparameters\n",
    "\n",
    "A k-NN model is defined by a set of parameters: nearest neighbors (K), distance metric (p), etc. These are called **hyperparameters**. We need to select the best model based on the optimal values of these hyperparameters, which we set manually. This process is called hyperparameter tuning.\n",
    "\n",
    "The model parameters are known as **hyperparameters** because the values of these parameters are used to control the learning process. By contrast, the values of other parameters are **learned**. In the k-NN model, there is no learning, thus we only tune the hyperparameters to create the optimal model.\n",
    "\n",
    "Hyperparameters are passed as arguments to the constructor of the estimator classes. We search the hyperparameter space for the best cross-validation score.\n",
    "\n",
    "We need to set the following hyperparameters to train a KNeighborsClassifier.\n",
    "\n",
    "\n",
    "- n_neighbors : int, optional (default = 5) Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "\n",
    "- weights : str or callable, optional (default = ‘uniform’) weight function used in prediction. Possible values:\n",
    "\n",
    "    -- ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "    \n",
    "    -- ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "    \n",
    "    -- [callable] : a user-defined function that accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "    \n",
    "\n",
    "- algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional. Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "    -- ‘ball_tree’ will use BallTree\n",
    "    \n",
    "    -- ‘kd_tree’ will use KDTree\n",
    "    \n",
    "    -- ‘brute’ will use a brute-force search.\n",
    "    \n",
    "    -- ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "    \n",
    "    -- Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "\n",
    "- leaf_size : int, optional (default = 30). Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "\n",
    "- p : integer, optional (default = 2)\n",
    "    \n",
    "    -- Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "\n",
    "- metric : string or callable, default ‘minkowski’. the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "\n",
    "\n",
    "- metric_params : dict, optional (default = None). Additional keyword arguments for the metric function.\n",
    "\n",
    "\n",
    "- n_jobs : int or None, optional (default=None). The number of parallel jobs to run for neighbors search. \n",
    "\n",
    "    -- n_jobs= None means 1 unless in a joblib.parallel_backend context. \n",
    "   \n",
    "    -- n_jobs = -1 means using all processors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The process of choosing the optimal hyperparameter values for a model (e.g., k) is known as model selection.\n",
    "\n",
    "First, we select a model based on just one hyperparameter, i.e., the number of nearest neighbors (k) by using default values for the remaining parameters of the model. This is quick and helps us to get a sense of the optimal model.\n",
    "\n",
    "Then, we select a model by finding a combination of the optimal hyperparameters. This is rigorous and more useful.\n",
    "\n",
    "\n",
    "### Model Selection: Choose Optimum k\n",
    "\n",
    "We determine the optimum K by evaluating the k-NN model for various values of k. We use the default setting for the other model parameters:\n",
    "\n",
    "- n_neighbors : default = 5\n",
    "\n",
    "- weights : default = ‘uniform’\n",
    "\n",
    "- algorithm : default = ‘auto’\n",
    "\n",
    "- p : default = 2\n",
    "    \n",
    "- metric : default = ‘minkowski’\n",
    "\n",
    "- metric_params : default = None\n",
    "\n",
    "- n_jobs : default=None\n",
    "\n",
    "We compute the performance on the training set as well as for the validation set. The validation performance is computed by using the **cross-validation** technique. The sklearn.model_selection.cross_val_score function is used for this purpose.\n",
    "\n",
    "The K-NN model is evaluated by computing a performance measure. There are various performance measures for classification problems.\n",
    "\n",
    "\n",
    "#### Performance Measure for Cross Validation\n",
    "\n",
    "The sklearn KNeighborsClassifier uses, by default, \"accuracy\" as the performance measure. In a skewed dataset, accuracy doesn't provide a good estimate of the performance of the model. We will have to use a confusion matrix, precision, recall, f1 score, etc.\n",
    "\n",
    "But for now, let's use KNeighborsClassifier's default accuracy score function to evaluate the model's performance for various values of K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the the range of k\n",
    "neighbors = np.arange(1,60)\n",
    "\n",
    "# Two arrays to store training and test accuracies\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "validation_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    \n",
    "    # Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # The \"score\" function returns the mean accuracy on the given train/test data and labels.\n",
    "    # Note that \"accuracy\" may not be a good performance measure in a skewed data set\n",
    "    # Thus, we need to do hyperparameter tuning by using better performance measures (e.g., f1 score, precision, recall)\n",
    "    \n",
    "    # Compute training accuracy \n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    \n",
    "    # Compute validation accuracy using cross-validation\n",
    "    # Depending on the value set for \"cv\", the cross_val_score function will return multiple score values\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    \n",
    "    # Compute the mean of the multiple score values\n",
    "    validation_accuracy[i] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Varying k: Number of Nearest Neighbors')\n",
    "plt.plot(neighbors, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('k (Number of Nearest Neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Find the value of \"K\" that gives max validation accuracy\n",
    "j = 0\n",
    "max_val_accuracy = validation_accuracy[j]\n",
    "max_k = 1\n",
    "\n",
    "for i in neighbors:\n",
    "    if(validation_accuracy[j] > max_val_accuracy):\n",
    "        max_val_accuracy = validation_accuracy[j]\n",
    "        max_k = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"Optimal k: \", max_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Choose a Combination of Optimal Hyperparameters via Hyperparameter Tuning\n",
    "\n",
    "The best way to do hyperparameter tuning is to use cross-validation.\n",
    "\n",
    "We will use Scikit-Learn’s **GridSearchCV** to search the combinations of hyperparameter values that provide the best performance.\n",
    "\n",
    "We need to tell which hyperparameters we want the GridSearchCV to experiment with, and what values to try out. \n",
    "\n",
    "         It will evaluate all the possible combinations of hyperparameter values using cross-validation. \n",
    "\n",
    "We will tune the following hyperparameters of the GridSearchCV model.\n",
    "\n",
    "- n_neighbors \n",
    "- weights \n",
    "- p \n",
    "    \n",
    "\n",
    "\n",
    "### GridSearchCV Parameters\n",
    "\n",
    "Following are the most frequenly used parameters by GridSearchCV.\n",
    "\n",
    "- estimator : estimator object. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
    "\n",
    "- param_grid : Dictionary with parameters names (string) as keys and lists of parameter settings to try as values, or a list of such dictionaries, in which case the grids spanned by each dictionary in the list are explored. This enables searching over any sequence of parameter settings.\n",
    "\n",
    "- scoring : string, callable, list/tuple, dict or None, default: None\n",
    "\n",
    "    -- A single string (see The scoring parameter: defining model evaluation rules) or a callable (see Defining your scoring strategy from metric functions) to evaluate the predictions on the test set.\n",
    "\n",
    "\n",
    "- n_jobs : int or None, optional (default=None). Number of jobs to run in parallel. \n",
    "\n",
    "    -- n_jobs= None means 1 unless in a joblib.parallel_backend context. \n",
    "   \n",
    "    -- n_jobs = -1 means using all processors. \n",
    "\n",
    "- cv : int. Determines the cross-validation splitting strategy. None, to use the default 3-fold cross validation.\n",
    "\n",
    "- verbose : integer. Controls the verbosity: the higher, the more messages.\n",
    "\n",
    "\n",
    "### Note: the scoring function\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For multiclass classification, we may use \"f1_micro\" scoring function. \n",
    "- The f1_micro function calculates metrics globally by counting the total true positives, true negatives, false negatives and false positives. More specifically, it computes the precision/recall pair for each class, then sum those to get total precision and recall, which are used to compute the F1 score. The micro average is suitable if there is class imbalance.\n",
    "\n",
    "- On the other hand, the f1_macro function computes the F1 score for each class, then computes the unweighted mean of all F1 scores. It does not take label imbalance into account.\n",
    "\n",
    "In the binary classification, F1 score function can be used. We may also use the precision, recall, roc_auc functions.\n",
    "\n",
    "\n",
    "\n",
    "### Note: Experimenting with the Mahalanobis Distance Metric\n",
    "\n",
    "We cannot use the Mahalanobis distance metric as a parameter for the grid search.\n",
    "\n",
    "Because for each iteration of the cross-validation, a new train fold is created which requires to compute the inverse of its covariance matrix.\n",
    "\n",
    "With the sklearn grid search we cannot compute the inverse of the covariance matrix dynamically for each training fold.\n",
    "\n",
    "Thus, unfortunately, we can't experiment with the Mahalanobis distance metric using the grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'n_neighbors': np.arange(1,50), 'p': [1, 2, 10, 50, 100, 500, 1000], \n",
    "              'weights': [\"uniform\", \"distance\"]}\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = GridSearchCV(knn_clf, param_grid, scoring='f1_micro', cv=5, verbose=3, n_jobs=-1)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_knn = knn_cv.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % knn_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_knn)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select The Best Model \n",
    "\n",
    "Using the optimal hyperparameter values, create the best model.\n",
    "Then, fit the model.\n",
    "\n",
    "## Note on Using Mahalanobis Distance Metric:\n",
    "\n",
    "The Mahalanobis distance metric works only with the brute force algorithm in sklearn. With this distance metric we tune only the following two hyperparameters.\n",
    "- weights: \"distance\", \"uniform\"\n",
    "- n_neighbors: int\n",
    "\n",
    "Also the data should not be standardized before using the Mahalanobis distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the Mahalanobis distance metric only the brute force algorithm works\n",
    "#knn = KNeighborsClassifier(weights=?, algorithm='brute', n_neighbors=?, metric = \"mahalanobis\", metric_params= {'V': ?})\n",
    "\n",
    "# Minkowski distance metric-based optimal model selected via hyperparameter tuning.\n",
    "# The Minkowski distance-based model (i.e., knn_cv) is already trained with the optimal hyperparameter values.\n",
    "# We can use the optimal model (knn_cv) for prediction.\n",
    "# Or we can use the optimal hyperparameter values to train a new model, as follows.\n",
    "\n",
    "knn = KNeighborsClassifier(**params_optimal_knn)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = knn.predict(X_train)\n",
    "\n",
    "train_accuracy_knn = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate Model Performance Using Cross-Validation\n",
    "\n",
    "Evaluate the model's performance using cross-validation. \n",
    "\n",
    "Use Scikit-Learn's cross_val_score function. \n",
    "\n",
    "Note that the \"scoring\" argument should be set based on the type of classification (binary/multiclass).\n",
    "\n",
    "\n",
    "### Benefit of Using Cross-Validation:\n",
    "\n",
    "Cross-validation allows us to get not only an estimate of the performance of our model, but also a measure of how precise this estimate is (i.e., its standard deviation). \n",
    "\n",
    "We would not have this information if we just used one validation set. \n",
    "\n",
    "But cross-validation comes at the cost of training the model several times, so it is not always possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Parameter for Classification:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# Note: For a skewed data set \"accuracy\" might not be a good choice for scoring\n",
    "scores = cross_val_score(knn, X_train, y_train, scoring='f1_micro', cv=5)\n",
    "print(scores)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute The Model Using Confusion Matrix for Training Data\n",
    "\n",
    "\n",
    "We use the cross_val_predict() function to performs cross-validation, \n",
    "\n",
    "However, unlike cross_val_score, it doesn't return the evaluation scores.\n",
    "\n",
    "Instead it returns the predictions made on each test fold. \n",
    "\n",
    "This means that we get a clean prediction for each instance in the training set.\n",
    "\n",
    "By “clean” we mean that the prediction is made by a model that never saw the data during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Model Using Test Data\n",
    "\n",
    "The KNeighborsClassifier model has a default \"score\" function that computes the accuracy of the model.\n",
    "\n",
    "Often the accuracy is not a good measure.\n",
    "\n",
    "We also create the confusion matrix for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The accuracy of the model\n",
    "test_accuracy_knn = knn.score(X_test, y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_knn)\n",
    "\n",
    "\n",
    "# No. of Correct Predictions\n",
    "y_test_predicted = knn.predict(X_test)\n",
    "print(\"\\nNo. of correct predictions (Test): %d/%d\" % (np.sum(y_test_predicted == y_test), len(y_test)))\n",
    "\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Test Data\n",
    "\n",
    "Using pandas crosstab, we create a better visualization of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, y_test_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Classification Metrics\n",
    "\n",
    "We can build a text report showing the main classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_predicted))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
